{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNHUDUgYQV24ghLAxyBoF++",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/khadkechetan/information_extraction/blob/main/Docvqa/Docvqa_imperia_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Owner: **Chetan Khadke** (khadkechetan@gmail.com)  âœŒ\n",
        "\n"
      ],
      "metadata": {
        "id": "FwwzBn78dx4z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Fjz6uWIdlP-"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git@2ef774211733f0acf8d3415f9284c49ef219e991\n",
        "!pip install torch\n",
        "!pip install datasets\n",
        "!pip install pillow\n",
        "!pip install sentencepiece  #  naver-clova-ix/donut-base-finetuned-docvqa based model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ],
      "metadata": {
        "id": "RWuxmIrdct4R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "funsd dataset for example ðŸ˜€\n",
        "\n",
        "To import own data please assign followings.\n",
        "- words into **words** \n",
        "- bounding box into **boxes**\n",
        "- image into **image**\n"
      ],
      "metadata": {
        "id": "uyvNeCEicoT6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from PIL import Image\n",
        "\n",
        "dataset = load_dataset(\"nielsr/funsd\", split=\"train\")\n",
        "example = dataset[0]\n",
        "question = \"What are the Manager comments??\"\n",
        "words = example[\"words\"]\n",
        "boxes = example[\"bboxes\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxyfxOaeRSsy",
        "outputId": "aa591f5f-e420-47c7-c2dd-c05b0b8c95a4"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset funsd (/root/.cache/huggingface/datasets/nielsr___funsd/funsd/1.0.0/8b0472b536a2dcb975d59a4fb9d6fea4e6a1abe260b7fed6f75301e168cbe595)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image = Image.open(example[\"image_path\"])"
      ],
      "metadata": {
        "id": "TsTbp9D2Ed2Y"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pipeline for **DOCVQA**"
      ],
      "metadata": {
        "id": "fuCmEnCIch_Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline(\n",
        "    \"document-question-answering\",\n",
        "    model=\"impira/layoutlm-invoices\",\n",
        "    framework = \"pt\",\n",
        "    # device=0  # use this for GPU\n",
        ")\n",
        "# model=\"naver-clova-ix/donut-base-finetuned-docvqa\"\n",
        "# model=\"impira/layoutlm-document-qa\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UjebuM55imMB",
        "outputId": "6391bb0f-8d7c-4185-d943-72c402bcad1c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at impira/layoutlm-invoices were not used when initializing LayoutLMForQuestionAnswering: ['token_classifier_head.bias', 'token_classifier_head.weight']\n",
            "- This IS expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create batches of words and bboxes."
      ],
      "metadata": {
        "id": "J_4RzsGGb6qL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words_bbox = []\n",
        "for word, bbox in zip(words,boxes):\n",
        "    words_bbox.append([word,bbox])"
      ],
      "metadata": {
        "id": "Pg5wA7QfUZ5h"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_bbox"
      ],
      "metadata": {
        "id": "6inoDc6iUxpx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predication = nlp(\n",
        "    image,\n",
        "    \"What is the advised solution?\",\n",
        "    word_boxes = words_bbox\n",
        ")"
      ],
      "metadata": {
        "id": "2rlygRVPdryv"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predication"
      ],
      "metadata": {
        "id": "ZdhJwEQ6g-TU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c580a5bf-6f98-4943-894a-9ce6becb9c75"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'score': 0.019657475873827934,\n",
              " 'answer': 'Discontinue coal retention analyses on licensee submitted product samples',\n",
              " 'start': 36,\n",
              " 'end': 44}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Using the pipeline"
      ],
      "metadata": {
        "id": "TiuDEyvQcZe1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoProcessor, LayoutLMForQuestionAnswering, AutoTokenizer\n",
        "\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"impira/layoutlm-document-qa\", add_prefix_space=True)\n",
        "model = LayoutLMForQuestionAnswering.from_pretrained(\"impira/layoutlm-invoices\")\n",
        "\n",
        "\n",
        "\n",
        "encoding = tokenizer(\n",
        "    question.split(), words, is_split_into_words=True, return_token_type_ids=True, return_tensors=\"pt\"\n",
        ")\n",
        "bbox = []\n",
        "for i, s, w in zip(encoding.input_ids[0], encoding.sequence_ids(0), encoding.word_ids(0)):\n",
        "    if s == 1:\n",
        "        bbox.append(boxes[w])\n",
        "    elif i == tokenizer.sep_token_id:\n",
        "        bbox.append([1000] * 4)\n",
        "    else:\n",
        "        bbox.append([0] * 4)\n",
        "encoding[\"bbox\"] = torch.tensor([bbox])\n",
        "\n",
        "word_ids = encoding.word_ids(0)\n",
        "outputs = model(**encoding)\n",
        "loss = outputs.loss\n",
        "start_scores = outputs.start_logits\n",
        "end_scores = outputs.end_logits\n",
        "start, end = word_ids[start_scores.argmax(-1)], word_ids[end_scores.argmax(-1)]\n",
        "print(\"-----------------------------------\")\n",
        "print(\" \".join(words[start : end + 1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl7BVveOSAUJ",
        "outputId": "73263c7c-558e-40ac-c8ef-2c9536164179"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at impira/layoutlm-invoices were not used when initializing LayoutLMForQuestionAnswering: ['token_classifier_head.bias', 'token_classifier_head.weight']\n",
            "- This IS expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing LayoutLMForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------\n",
            "Manager, please contact suggester and forward comments to the Quality Council.\n"
          ]
        }
      ]
    }
  ]
}